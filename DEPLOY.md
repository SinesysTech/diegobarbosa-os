# Deploy do Sinesys

Este documento descreve como fazer o deploy da stack Sinesys em diferentes ambientes.

## Arquitetura de Servi√ßos

O Sinesys √© composto por **3 servi√ßos independentes**, cada um em seu pr√≥prio reposit√≥rio:

| Servi√ßo | Reposit√≥rio | Descri√ß√£o | Porta | WebSocket |
|---------|-------------|-----------|-------|-----------|
| **sinesys_app** | Este repo | Frontend Next.js + API | 3000 | ‚ùå |
| **sinesys_mcp** | sinesys-mcp-server | MCP Server para agentes IA | 3001 | ‚ùå |
| **sinesys_browser** | sinesys-browser-server | Firefox (scraping PJE) | 3000 | ‚úÖ |

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                        Servidor                              ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ   ‚îÇ  sinesys_app ‚îÇ   ‚îÇ sinesys_mcp  ‚îÇ   ‚îÇsinesys_browser‚îÇ   ‚îÇ
‚îÇ   ‚îÇ  (Next.js)   ‚îÇ   ‚îÇ  (Node.js)   ‚îÇ   ‚îÇ   (Firefox)   ‚îÇ   ‚îÇ
‚îÇ   ‚îÇ  :3000       ‚îÇ   ‚îÇ  :3001       ‚îÇ   ‚îÇ  :3000 (WS)   ‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ          ‚îÇ                  ‚îÇ                    ‚îÇ           ‚îÇ
‚îÇ          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò           ‚îÇ
‚îÇ                             ‚îÇ                                ‚îÇ
‚îÇ                     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                       ‚îÇ
‚îÇ                     ‚îÇ   Supabase    ‚îÇ                       ‚îÇ
‚îÇ                     ‚îÇ Redis MongoDB ‚îÇ                       ‚îÇ
‚îÇ                     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## Deploy no CapRover

### Pr√©-requisitos

- CapRover instalado e configurado
- CLI do CapRover (`npm install -g caprover`)
- Acesso ao dashboard do CapRover
- Os 3 reposit√≥rios clonados localmente

### Passo 1: Criar os Apps no CapRover

Acesse o dashboard do CapRover e crie **3 apps**:

| Nome do App | Reposit√≥rio | HTTP Port | WebSocket |
|-------------|-------------|-----------|-----------|
| `sinesys` | Este repo | 3000 | ‚ùå |
| `sinesys-mcp` | sinesys-mcp-server | 3001 | ‚ùå |
| `sinesys-browser` | sinesys-browser-server | 3000 | ‚úÖ |

> ‚ö†Ô∏è **Importante**: Habilite WebSocket Support apenas para `sinesys-browser`!

### Passo 2: Deploy do Browser Service (Firefox)

**No reposit√≥rio sinesys-browser-server:**

```bash
# Clone o reposit√≥rio
git clone https://github.com/seu-org/sinesys-browser-server.git
cd sinesys-browser-server

# Login no CapRover
caprover login

# Deploy
caprover deploy -a sinesys-browser
```

**Vari√°veis de ambiente:**
```env
PORT=3000
BROWSER_TOKEN=seu_token_opcional
```

**Configura√ß√µes importantes:**
- Container HTTP Port: `3000`
- WebSocket Support: ‚úÖ **Habilitar**
- Memory: 2048MB (m√≠nimo)

### Passo 3: Deploy do MCP Server

**No reposit√≥rio sinesys-mcp-server:**

```bash
cd sinesys-mcp-server

# Login no CapRover (se ainda n√£o fez)
caprover login

# Deploy
caprover deploy -a sinesys-mcp
```

**Vari√°veis de ambiente:**
```env
NODE_ENV=production
PORT=3001
SINESYS_API_URL=http://srv-captain--sinesys:3000
SINESYS_API_KEY=sua_api_key
```

### Passo 4: Deploy do App Principal

**Neste reposit√≥rio (Sinesys):**

```bash
# Login no CapRover
caprover login

# Deploy
caprover deploy -a sinesys
```

> **Importante**: O CapRover pedir√° os build args. Informe:
> - `NEXT_PUBLIC_SUPABASE_URL`
> - `NEXT_PUBLIC_SUPABASE_PUBLISHABLE_OR_ANON_KEY`
> ‚ö†Ô∏è Importante: Antes de configurar deploy, leia a se√ß√£o 'Prevenindo M√∫ltiplos Builds Simult√¢neos' para evitar problemas.

**Vari√°veis de ambiente:**
```env
NODE_ENV=production
NEXT_TELEMETRY_DISABLED=1
PORT=3000
HOSTNAME=0.0.0.0

# Supabase
NEXT_PUBLIC_SUPABASE_URL=https://xxx.supabase.co
NEXT_PUBLIC_SUPABASE_PUBLISHABLE_OR_ANON_KEY=sua_anon_key
SUPABASE_SECRET_KEY=sua_secret_key

# Browser Service (comunica√ß√£o interna CapRover)
BROWSER_WS_ENDPOINT=ws://srv-captain--sinesys-browser:3000
BROWSER_SERVICE_URL=http://srv-captain--sinesys-browser:3000

# Redis (opcional)
ENABLE_REDIS_CACHE=true
REDIS_URL=redis://host:port

# MongoDB (opcional)
MONGODB_URL=mongodb://...
MONGODB_DATABASE=sinesys
```

### Passo 5: Configurar Dom√≠nios e HTTPS

No dashboard do CapRover:

| App | Dom√≠nio | HTTPS |
|-----|---------|-------|
| sinesys | app.seudominio.com.br | ‚úÖ |
| sinesys-mcp | mcp.seudominio.com.br (opcional) | ‚úÖ |
| sinesys-browser | (n√£o expor) | ‚Äî |

---

## Deploy com Docker Compose (Local)

Para desenvolvimento local, voc√™ pode usar o `docker-compose.yml` simplificado:

```bash
# Subir apenas o app (sem mcp e browser)
docker-compose up -d

# Ver logs
docker-compose logs -f

# Parar
docker-compose down
```

> **Nota**: Para desenvolvimento completo com os 3 servi√ßos, clone os outros reposit√≥rios e suba-os separadamente.

---

## Comunica√ß√£o entre Servi√ßos

### No CapRover
Use o formato: `srv-captain--NOME_DO_APP`

```
http://srv-captain--sinesys:3000
http://srv-captain--sinesys-mcp:3001
ws://srv-captain--sinesys-browser:3000
```

### No Docker Compose Local
Use o nome do servi√ßo:

```
http://sinesys_app:3000
```

---

## Build Args vs Environment Variables

### Build Args (tempo de build)
Usados apenas durante `docker build`:
- `NEXT_PUBLIC_SUPABASE_URL`
- `NEXT_PUBLIC_SUPABASE_PUBLISHABLE_OR_ANON_KEY`

> **Por qu√™?** Vari√°veis `NEXT_PUBLIC_*` s√£o "inlined" no c√≥digo durante o build do Next.js.

### Environment Variables (runtime)
Usadas quando o container est√° rodando:
- `SUPABASE_SECRET_KEY`
- `BROWSER_WS_ENDPOINT`
- `REDIS_URL`
- etc.

---

## Troubleshooting

### Build falha com OOM (Out of Memory)

O Next.js pode consumir muita mem√≥ria durante o build. Solu√ß√µes:

1. **Aumentar mem√≥ria do build no CapRover**:
   - App Configs > Build Timeout & Memory
   - Aumente para 4096MB ou mais

2. **Usar swap no servidor**:
   ```bash
   sudo fallocate -l 4G /swapfile
   sudo chmod 600 /swapfile
   sudo mkswap /swapfile
   sudo swapon /swapfile
   ```

3. **Build em m√°quina externa**:
   ```bash
   docker build -t sinesys:latest .
   docker tag sinesys:latest seu-registry/sinesys:latest
   docker push seu-registry/sinesys:latest
   ```
   E no CapRover, use "Deploy via ImageName".
   üí° Dica: Se o OOM ocorre durante m√∫ltiplos builds simult√¢neos, veja a se√ß√£o 'Prevenindo M√∫ltiplos Builds Simult√¢neos'.

### Container reinicia constantemente

Verifique os logs no dashboard do CapRover: App > App Logs

### Browser Service n√£o conecta

1. Verifique se o app `sinesys-browser` est√° rodando
2. Confirme que **WebSocket est√° habilitado** no app
3. Teste a conex√£o:
   ```bash
   curl http://srv-captain--sinesys-browser:3000/health
   ```

## Prevenindo M√∫ltiplos Builds Simult√¢neos

M√∫ltiplos builds simult√¢neos podem causar **Out of Memory (OOM)** no servidor, especialmente quando cada build consome ~2GB de RAM. Isso acontece quando webhooks duplicados ou configura√ß√µes incorretas no CapRover triggeram builds em paralelo.

### Diagn√≥stico de Webhooks Duplicados

Para identificar webhooks duplicados no GitHub:

1. Acesse o reposit√≥rio no GitHub
2. V√° para **Settings ‚Üí Webhooks**
3. Verifique a lista de webhooks ativos
4. Procure por m√∫ltiplos webhooks apontando para a mesma URL do CapRover

**Como identificar duplicados:**
- Mesmo **Payload URL** (ex: `https://captain.yourdomain.com/api/v2/user/apps/webhooks/trigger`)
- Mesmo **Content type** e **Secret** (se aplic√°vel)
- Webhooks com status "Active" para o mesmo app

**Comando para listar webhooks via GitHub CLI:**
```bash
gh api repos/{owner}/{repo}/hooks
```

> ‚ö†Ô∏è **Importante**: Cada app no CapRover deve ter apenas **uma URL de webhook ativa** no GitHub. M√∫ltiplos webhooks para o mesmo app causam builds simult√¢neos.

### Configura√ß√£o Correta no CapRover

O CapRover oferece duas op√ß√µes principais para deploy autom√°tico: **"Deploy via GitHub"** e **"Deploy Triggers (Webhook)"**. A diferen√ßa √©:

- **Deploy via GitHub**: O CapRover monitora o reposit√≥rio diretamente (requer credenciais Git configuradas)
- **Deploy Triggers (Webhook)**: Usa webhooks externos (como do GitHub) para triggerar builds

**Op√ß√£o A (Recomendada): Usar apenas "Deploy Triggers (Webhook)" do CapRover**
- No dashboard do CapRover: Apps ‚Üí [seu-app] ‚Üí Deployment ‚Üí Desabilitar "Deploy via GitHub"
- No GitHub: Configure apenas **1 webhook** com a URL fornecida pelo CapRover (Deployment ‚Üí Deploy Triggers ‚Üí Copy Webhook URL)

**Op√ß√£o B: Usar apenas "Deploy via GitHub" (sem webhook externo)**
- No GitHub: Remova todos os webhooks relacionados ao CapRover
- No CapRover: Configure credenciais Git (Deployment ‚Üí Deploy via GitHub) e habilite o monitoramento

> üö´ **NUNCA use ambos simultaneamente** (Deploy via GitHub + Webhook): Isso causa builds duplicados e simult√¢neos, levando a OOM.

### Verifica√ß√£o de Configura√ß√£o Atual

Para verificar a configura√ß√£o atual no CapRover:

1. Acesse o dashboard: Apps ‚Üí [seu-app] ‚Üí Deployment
2. Verifique se "Deploy via GitHub" est√° habilitado
3. Verifique se h√° webhook configurado em "Deploy Triggers"
4. Se ambos estiverem ativos, **desabilite um deles** (recomendado: mantenha apenas o webhook)

### Boas Pr√°ticas para Deploy

- Fa√ßa commits at√¥micos: Evite m√∫ltiplos pushes em sequ√™ncia r√°pida
- Aguarde a conclus√£o do build anterior antes de fazer novo push
- Use `git push --force` com cautela: Pode triggerar m√∫ltiplos builds se houver conflitos
- Considere usar branches de staging para testes antes de deploy em produ√ß√£o

### Checklist de Verifica√ß√£o Pr√©-Deploy

Antes de cada deploy, verifique:

- [ ] Existe apenas **1 webhook ativo** no GitHub para este app
- [ ] Apenas **uma op√ß√£o de deploy** est√° habilitada no CapRover (webhook OU auto-deploy)
- [ ] N√£o h√° builds em andamento antes de fazer push
- [ ] O servidor tem mem√≥ria suficiente (m√≠nimo 4GB dispon√≠vel)

### Troubleshooting de M√∫ltiplos Builds

**Sintoma**: Logs mostram "A build for [app] was queued, it's now being replaced with a new build..." ou builds simult√¢neos causando OOM.

**Diagn√≥stico**:
- No GitHub: Settings ‚Üí Webhooks ‚Üí Recent Deliveries ‚Üí Procure m√∫ltiplas requisi√ß√µes para o mesmo commit SHA
- No CapRover: Verifique logs do app para identificar origem dos triggers (webhook vs auto-deploy)

**Solu√ß√£o**:
- Remova webhooks duplicados no GitHub
- Desabilite auto-deploy se estiver usando webhook manual
- Aumente mem√≥ria do servidor ou adicione swap (ver se√ß√£o "Build falha com OOM")

### Exemplo de Configura√ß√£o Correta

```
‚úÖ CONFIGURA√á√ÉO RECOMENDADA:
- GitHub: 1 webhook ativo (URL do CapRover)
- CapRover: Deploy Triggers habilitado
- CapRover: Deploy via GitHub DESABILITADO

‚ùå CONFIGURA√á√ÉO INCORRETA (causa m√∫ltiplos builds):
- GitHub: 2+ webhooks ativos
- CapRover: Deploy Triggers E Deploy via GitHub ambos habilitados
```

---

## Recursos Recomendados

| Servi√ßo | RAM M√≠nima | RAM Recomendada | CPU |
|---------|------------|-----------------|-----|
| sinesys_app | 512MB | 1GB | 1 core |
| sinesys_mcp | 128MB | 256MB | 0.5 core |
| sinesys_browser | 1GB | 2GB | 1-2 cores |

**Total recomendado**: VPS com 4GB RAM, 2-4 cores

---

## Vari√°veis de Ambiente Completas

### App Principal (sinesys)

```env
# Supabase (obrigat√≥rio)
NEXT_PUBLIC_SUPABASE_URL=https://xxx.supabase.co
NEXT_PUBLIC_SUPABASE_PUBLISHABLE_OR_ANON_KEY=eyJ...
SUPABASE_SECRET_KEY=eyJ...

# API Key (para comunica√ß√£o entre servi√ßos)
SERVICE_API_KEY=sua_api_key_segura

# Browser Service
BROWSER_WS_ENDPOINT=ws://srv-captain--sinesys-browser:3000
BROWSER_SERVICE_URL=http://srv-captain--sinesys-browser:3000
BROWSER_SERVICE_TOKEN=opcional_token_seguranca

# Redis (opcional)
ENABLE_REDIS_CACHE=true
REDIS_URL=redis://user:password@host:6379

# MongoDB (opcional)
MONGODB_URL=mongodb://user:password@host:27017
MONGODB_DATABASE=sinesys

# 2FAuth (para OTP do PJE)
TWOFAUTH_API_URL=https://seu-2fauth.com
TWOFAUTH_API_TOKEN=seu_token
TWOFAUTH_ACCOUNT_ID=id_da_conta
```

### MCP Server (sinesys-mcp)

```env
NODE_ENV=production
PORT=3001
SINESYS_API_URL=http://srv-captain--sinesys:3000
SINESYS_API_KEY=sua_api_key_segura
```

### Browser Server (sinesys-browser)

```env
PORT=3000
BROWSER_TOKEN=opcional_token_seguranca
```